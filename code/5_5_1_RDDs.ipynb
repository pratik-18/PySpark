{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6819383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/spark/spark-3.2.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/03/05 15:13:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e96117e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bca9b6",
   "metadata": {},
   "source": [
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    green\n",
    "WHERE\n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01141b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df_green \\\n",
    "    .select('lpep_pickup_datetime', 'PULocationID', 'total_amount') \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8198368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb19735",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(year=2020, month=1, day=1)\n",
    "\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5648ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 12, 18, 15, 4), PULocationID=41, total_amount=7.88)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = rdd.take(10)\n",
    "row = rows[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04046ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_function(row): \n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e2de60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 12, 18, 0), 41), (7.88, 1)),\n",
       " ((datetime.datetime(2020, 1, 31, 20, 0), 173), (8.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 7, 8, 0), 74), (23.46, 1)),\n",
       " ((datetime.datetime(2020, 1, 15, 14, 0), 25), (7.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 31, 10, 0), 259), (25.54, 1)),\n",
       " ((datetime.datetime(2020, 1, 18, 17, 0), 177), (13.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 17, 20, 0), 65), (11.16, 1)),\n",
       " ((datetime.datetime(2020, 1, 13, 10, 0), 165), (20.56, 1)),\n",
       " ((datetime.datetime(2020, 1, 7, 15, 0), 170), (49.05, 1)),\n",
       " ((datetime.datetime(2020, 1, 10, 11, 0), 74), (9.56, 1))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(mapper_function) \\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1584d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_function(left_value, right_value):\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "153f0e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 8, 20, 0), 75), (932.3999999999996, 66)),\n",
       " ((datetime.datetime(2020, 1, 16, 18, 0), 41), (591.8100000000001, 54)),\n",
       " ((datetime.datetime(2020, 1, 23, 10, 0), 43), (315.40000000000003, 19)),\n",
       " ((datetime.datetime(2020, 1, 8, 16, 0), 74), (1398.779999999999, 74)),\n",
       " ((datetime.datetime(2020, 1, 21, 8, 0), 17), (90.17999999999999, 5)),\n",
       " ((datetime.datetime(2020, 1, 28, 8, 0), 121), (45.11, 2)),\n",
       " ((datetime.datetime(2020, 1, 4, 15, 0), 25), (457.37000000000006, 25)),\n",
       " ((datetime.datetime(2020, 1, 2, 16, 0), 166), (555.48, 32)),\n",
       " ((datetime.datetime(2020, 1, 24, 1, 0), 129), (155.73000000000002, 12)),\n",
       " ((datetime.datetime(2020, 1, 18, 19, 0), 82), (356.60000000000014, 28))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(mapper_function) \\\n",
    "    .reduceByKey(reducer_function) \\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "049e6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729b5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "RevenueRow = namedtuple('RevenueRow', ['hour', 'zone', 'revenue', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a36ea63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "        hour=row[0][0], \n",
    "        zone=row[0][1],\n",
    "        revenue=row[1][0],\n",
    "        count=row[1][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e55db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2cfc81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aecd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(mapper_function) \\\n",
    "    .reduceByKey(reducer_function) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF(result_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "378a2796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+-----+\n",
      "|               hour|zone|           revenue|count|\n",
      "+-------------------+----+------------------+-----+\n",
      "|2020-01-08 20:00:00|  75| 932.3999999999996|   66|\n",
      "|2020-01-16 18:00:00|  41| 591.8100000000001|   54|\n",
      "|2020-01-23 10:00:00|  43|315.40000000000003|   19|\n",
      "|2020-01-08 16:00:00|  74| 1398.779999999999|   74|\n",
      "|2020-01-21 08:00:00|  17| 90.17999999999999|    5|\n",
      "|2020-01-28 08:00:00| 121|             45.11|    2|\n",
      "|2020-01-04 15:00:00|  25|457.37000000000006|   25|\n",
      "|2020-01-02 16:00:00| 166|            555.48|   32|\n",
      "|2020-01-24 01:00:00| 129|155.73000000000002|   12|\n",
      "|2020-01-18 19:00:00|  82|356.60000000000014|   28|\n",
      "|2020-01-12 12:00:00| 254|             81.74|    4|\n",
      "|2020-01-12 15:00:00|  74|1287.1899999999991|   85|\n",
      "|2020-01-24 18:00:00| 130|            546.78|   29|\n",
      "|2020-01-08 15:00:00|  95|            441.29|   39|\n",
      "|2020-01-07 06:00:00|  95|             85.64|    3|\n",
      "|2020-01-07 19:00:00| 238|             63.31|    2|\n",
      "|2020-01-09 18:00:00|  65|            302.82|   20|\n",
      "|2020-01-07 20:00:00|  69|46.720000000000006|    3|\n",
      "|2020-01-05 12:00:00|  35|481.70000000000005|   18|\n",
      "|2020-01-15 21:00:00|  66| 527.7900000000001|   26|\n",
      "+-------------------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    " df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21801d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet('tmp/green-revenue-rdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "073ab519",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['VendorID', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance']\n",
    "\n",
    "duration_rdd = df_green \\\n",
    "    .select(columns) \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59b47199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b49a3f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy model to predict how long the trip will take\n",
    "def model_predict(df):\n",
    "    #y_pred = model.predict(df)\n",
    "    y_pred = df.trip_distance * 5\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a366a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_in_batch(rows):\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    predictions = model_predict(df)\n",
    "    df['predicted_duration'] = predictions\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e06041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_predicts = duration_rdd \\\n",
    "    .mapPartitions(apply_model_in_batch)\\\n",
    "    .toDF() \\\n",
    "    .drop('Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15a68724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|predicted_duration|\n",
      "+------------------+\n",
      "|3.9000000000000004|\n",
      "|               4.9|\n",
      "|              13.5|\n",
      "|               4.0|\n",
      "|             11.65|\n",
      "|13.100000000000001|\n",
      "|5.6499999999999995|\n",
      "| 6.800000000000001|\n",
      "|             55.75|\n",
      "|               8.9|\n",
      "|               5.0|\n",
      "|             13.75|\n",
      "|               5.5|\n",
      "|             19.05|\n",
      "|              9.25|\n",
      "|              45.7|\n",
      "|               5.2|\n",
      "| 5.699999999999999|\n",
      "|              5.75|\n",
      "|4.6000000000000005|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/06 07:44:13 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 34895468 ms exceeds timeout 120000 ms\n",
      "23/03/06 07:44:14 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "df_predicts.select('predicted_duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ded1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
